"""
Image Converter FastAPI Router
Endpoints para convers√£o de imagens com sistema de pagamento
"""

from fastapi import APIRouter, File, UploadFile, Form, HTTPException, BackgroundTasks
from fastapi.responses import FileResponse, JSONResponse
from typing import Optional, List
import os
import tempfile
import asyncio
from pathlib import Path
import logging
import json
from datetime import datetime

# Import do conversor (com fallback se PIL n√£o estiver dispon√≠vel)
try:
    from app.converters.image import ImageConverter
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    ImageConverter = None

from app.core.database import get_db
from app.models.orders import Order
from app.models.files import FileUpload
from app.core.security import create_access_token, verify_token
from app.tasks import convert_image_task  # Celery task

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/convert/image", tags=["Image Conversion"])

# Configura√ß√µes
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
ALLOWED_EXTENSIONS = {'.png', '.jpg', '.jpeg', '.webp', '.bmp', '.gif', '.tiff', '.tif', '.pdf'}
OUTPUT_FORMATS = {'.png', '.jpg', '.jpeg', '.webp', '.pdf'}

# Pre√ßos (R$)
PRICING = {
    'basic': 2.00,
    'compress': 3.00,
    'resize': 3.00,
    'premium': 5.00,
    'batch': 1.50
}

@router.get("/formats")
async def get_supported_formats():
    """Retorna formatos suportados e pre√ßos"""
    return {
        "supported_input": list(ALLOWED_EXTENSIONS),
        "supported_output": list(OUTPUT_FORMATS),
        "pricing": PRICING,
        "max_file_size_mb": MAX_FILE_SIZE // (1024 * 1024),
        "pil_available": PIL_AVAILABLE,
        "status": "active"
    }

@router.post("/upload")
async def upload_image_for_conversion(
    file: UploadFile = File(...),
    target_format: str = Form(...),
    quality: Optional[int] = Form(85),
    max_width: Optional[int] = Form(None),
    max_height: Optional[int] = Form(None),
    apply_compression: bool = Form(True),
    db=None
):
    """
    Upload de imagem para convers√£o
    
    Args:
        file: Arquivo de imagem
        target_format: Formato de destino (png, jpg, webp, pdf)
        quality: Qualidade para JPG/WebP (1-100)
        max_width: Largura m√°xima 
        max_height: Altura m√°xima
        apply_compression: Aplicar compress√£o
    
    Returns:
        Informa√ß√µes do upload e pre√ßo
    """
    try:
        # Valida√ß√µes b√°sicas
        if not file.filename:
            raise HTTPException(400, "Nome do arquivo √© obrigat√≥rio")
        
        # Verificar extens√£o
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in ALLOWED_EXTENSIONS:
            raise HTTPException(400, f"Formato n√£o suportado: {file_ext}")
        
        if f".{target_format}" not in OUTPUT_FORMATS:
            raise HTTPException(400, f"Formato de sa√≠da inv√°lido: {target_format}")
        
        # Verificar tamanho
        file_content = await file.read()
        if len(file_content) > MAX_FILE_SIZE:
            raise HTTPException(400, f"Arquivo muito grande: {len(file_content)} bytes > {MAX_FILE_SIZE}")
        
        # Salvar arquivo temporariamente
        upload_dir = "uploads/incoming"
        os.makedirs(upload_dir, exist_ok=True)
        
        file_id = f"img_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file.filename}"
        temp_path = os.path.join(upload_dir, file_id)
        
        with open(temp_path, "wb") as f:
            f.write(file_content)
        
        # Calcular pre√ßo
        has_resize = max_width is not None or max_height is not None
        
        if apply_compression and has_resize:
            conversion_type = "premium"
        elif apply_compression:
            conversion_type = "compress"
        elif has_resize:
            conversion_type = "resize"
        else:
            conversion_type = "basic"
        
        price = PRICING[conversion_type]
        
        # Criar registro de upload
        upload_data = {
            "file_id": file_id,
            "original_filename": file.filename,
            "file_path": temp_path,
            "file_size": len(file_content),
            "input_format": file_ext,
            "target_format": target_format,
            "conversion_params": {
                "quality": quality,
                "max_width": max_width,
                "max_height": max_height,
                "compression": apply_compression,
                "type": conversion_type
            },
            "price": price,
            "status": "uploaded",
            "created_at": datetime.utcnow().isoformat()
        }
        
        # Salvar metadados
        metadata_path = os.path.join(upload_dir, f"{file_id}.json")
        with open(metadata_path, "w") as f:
            json.dump(upload_data, f, indent=2)
        
        return JSONResponse({
            "success": True,
            "file_id": file_id,
            "original_filename": file.filename,
            "file_size": len(file_content),
            "input_format": file_ext,
            "target_format": target_format,
            "conversion_type": conversion_type,
            "price": price,
            "price_formatted": f"R$ {price:.2f}",
            "next_step": "payment",
            "payment_url": f"/payment/pix/{file_id}",
            "pil_available": PIL_AVAILABLE
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro no upload: {e}")
        raise HTTPException(500, f"Erro interno: {str(e)}")

@router.post("/batch-upload")
async def batch_upload_images(
    files: List[UploadFile] = File(...),
    target_format: str = Form(...),
    quality: Optional[int] = Form(85),
    max_width: Optional[int] = Form(None),
    max_height: Optional[int] = Form(None),
    apply_compression: bool = Form(True)
):
    """Upload em lote de imagens para convers√£o"""
    try:
        if len(files) < 1:
            raise HTTPException(400, "Pelo menos 1 arquivo √© obrigat√≥rio")
        
        if len(files) > 20:
            raise HTTPException(400, "M√°ximo 20 arquivos por lote")
        
        batch_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        upload_dir = f"uploads/incoming/{batch_id}"
        os.makedirs(upload_dir, exist_ok=True)
        
        uploaded_files = []
        total_size = 0
        
        for idx, file in enumerate(files):
            if not file.filename:
                continue
                
            file_ext = Path(file.filename).suffix.lower()
            if file_ext not in ALLOWED_EXTENSIONS:
                continue
            
            file_content = await file.read()
            if len(file_content) > MAX_FILE_SIZE:
                continue
            
            file_id = f"img_{idx:02d}_{file.filename}"
            temp_path = os.path.join(upload_dir, file_id)
            
            with open(temp_path, "wb") as f:
                f.write(file_content)
            
            uploaded_files.append({
                "file_id": file_id,
                "filename": file.filename,
                "size": len(file_content),
                "format": file_ext,
                "path": temp_path
            })
            
            total_size += len(file_content)
        
        if not uploaded_files:
            raise HTTPException(400, "Nenhum arquivo v√°lido encontrado")
        
        # Pre√ßo em lote
        file_count = len(uploaded_files)
        if file_count >= 5:
            unit_price = PRICING['batch']
        else:
            has_resize = max_width is not None or max_height is not None
            if apply_compression and has_resize:
                unit_price = PRICING['premium']
            elif apply_compression:
                unit_price = PRICING['compress']
            elif has_resize:
                unit_price = PRICING['resize']
            else:
                unit_price = PRICING['basic']
        
        total_price = unit_price * file_count
        
        # Salvar metadados do lote
        batch_data = {
            "batch_id": batch_id,
            "files": uploaded_files,
            "total_files": file_count,
            "total_size": total_size,
            "target_format": target_format,
            "conversion_params": {
                "quality": quality,
                "max_width": max_width,
                "max_height": max_height,
                "compression": apply_compression
            },
            "unit_price": unit_price,
            "total_price": total_price,
            "is_batch_discount": file_count >= 5,
            "status": "uploaded",
            "created_at": datetime.utcnow().isoformat()
        }
        
        metadata_path = os.path.join(upload_dir, "batch_metadata.json")
        with open(metadata_path, "w") as f:
            json.dump(batch_data, f, indent=2)
        
        return JSONResponse({
            "success": True,
            "batch_id": batch_id,
            "files_processed": file_count,
            "total_size": total_size,
            "unit_price": unit_price,
            "total_price": total_price,
            "price_formatted": f"R$ {total_price:.2f}",
            "discount_applied": file_count >= 5,
            "files": [{"filename": f["filename"], "size": f["size"]} for f in uploaded_files],
            "next_step": "payment",
            "payment_url": f"/payment/pix/{batch_id}",
            "pil_available": PIL_AVAILABLE
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro no upload em lote: {e}")
        raise HTTPException(500, f"Erro interno: {str(e)}")

@router.post("/convert/{file_id}")
async def start_conversion(
    file_id: str,
    background_tasks: BackgroundTasks
):
    """
    Iniciar convers√£o ap√≥s pagamento confirmado
    """
    try:
        # Verificar se arquivo existe
        upload_dir = "uploads/incoming"
        metadata_path = os.path.join(upload_dir, f"{file_id}.json")
        
        if not os.path.exists(metadata_path):
            raise HTTPException(404, "Arquivo n√£o encontrado")
        
        # Carregar metadados
        with open(metadata_path, "r") as f:
            metadata = json.load(f)
        
        # Verificar se pagamento foi confirmado (simplificado)
        # TODO: Integrar com sistema real de verifica√ß√£o de pagamento
        
        # Simular convers√£o (placeholder para quando PIL estiver dispon√≠vel)
        if PIL_AVAILABLE:
            # Adicionar tarefa em background
            background_tasks.add_task(convert_image_async, file_id, metadata)
        else:
            # Mock conversion para demonstra√ß√£o
            await mock_conversion(file_id, metadata)
        
        return JSONResponse({
            "success": True,
            "file_id": file_id,
            "status": "converting",
            "message": "Convers√£o iniciada",
            "check_status_url": f"/convert/image/status/{file_id}",
            "pil_available": PIL_AVAILABLE
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro iniciando convers√£o: {e}")
        raise HTTPException(500, f"Erro interno: {str(e)}")

@router.get("/status/{file_id}")
async def check_conversion_status(file_id: str):
    """Verificar status da convers√£o"""
    try:
        # Verificar nos diferentes diret√≥rios
        for status_dir in ["incoming", "processing", "converted", "failed"]:
            metadata_path = os.path.join("uploads", status_dir, f"{file_id}.json")
            if os.path.exists(metadata_path):
                with open(metadata_path, "r") as f:
                    metadata = json.load(f)
                
                return JSONResponse({
                    "success": True,
                    "file_id": file_id,
                    "status": metadata.get("status", status_dir),
                    "original_filename": metadata.get("original_filename"),
                    "target_format": metadata.get("target_format"),
                    "created_at": metadata.get("created_at"),
                    "completed_at": metadata.get("completed_at"),
                    "download_url": f"/convert/image/download/{file_id}" if status_dir == "converted" else None,
                    "error": metadata.get("error") if status_dir == "failed" else None
                })
        
        raise HTTPException(404, "Arquivo n√£o encontrado")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro verificando status: {e}")
        raise HTTPException(500, f"Erro interno: {str(e)}")

@router.get("/download/{file_id}")
async def download_converted_image(file_id: str):
    """Download da imagem convertida"""
    try:
        # Verificar se convers√£o est√° completa
        metadata_path = os.path.join("uploads/converted", f"{file_id}.json")
        if not os.path.exists(metadata_path):
            raise HTTPException(404, "Arquivo convertido n√£o encontrado")
        
        with open(metadata_path, "r") as f:
            metadata = json.load(f)
        
        output_path = metadata.get("output_path")
        if not output_path or not os.path.exists(output_path):
            raise HTTPException(404, "Arquivo de sa√≠da n√£o encontrado")
        
        # Determinar nome do arquivo
        original_name = Path(metadata.get("original_filename", file_id))
        target_format = metadata.get("target_format", "png")
        download_name = f"{original_name.stem}_converted.{target_format}"
        
        return FileResponse(
            output_path,
            filename=download_name,
            media_type="application/octet-stream"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erro no download: {e}")
        raise HTTPException(500, f"Erro interno: {str(e)}")

# Fun√ß√µes auxiliares
async def convert_image_async(file_id: str, metadata: dict):
    """Convers√£o ass√≠ncrona de imagem"""
    try:
        if not PIL_AVAILABLE:
            await mock_conversion(file_id, metadata)
            return
        
        # TODO: Implementar convers√£o real com PIL
        converter = ImageConverter()
        input_path = metadata["file_path"]
        
        # Preparar sa√≠da
        output_dir = "uploads/converted"
        os.makedirs(output_dir, exist_ok=True)
        
        target_format = metadata["target_format"]
        output_path = os.path.join(output_dir, f"{file_id}_converted.{target_format}")
        
        # Par√¢metros de convers√£o
        params = metadata.get("conversion_params", {})
        
        # Executar convers√£o
        result = converter.convert_single(
            input_path,
            output_path,
            target_format=target_format,
            quality=params.get("quality", 85),
            max_width=params.get("max_width"),
            max_height=params.get("max_height"),
            compression=params.get("compression", True)
        )
        
        # Atualizar metadados
        if result["success"]:
            metadata.update({
                "status": "completed",
                "output_path": output_path,
                "completed_at": datetime.utcnow().isoformat(),
                "conversion_stats": result
            })
            
            # Salvar metadados finais
            final_metadata_path = os.path.join(output_dir, f"{file_id}.json")
            with open(final_metadata_path, "w") as f:
                json.dump(metadata, f, indent=2)
        else:
            raise Exception(result.get("error", "Convers√£o falhou"))
            
    except Exception as e:
        logger.error(f"Erro na convers√£o ass√≠ncrona: {e}")
        # Mover para diret√≥rio de falhas
        await handle_conversion_error(file_id, metadata, str(e))

async def mock_conversion(file_id: str, metadata: dict):
    """Mock de convers√£o para demonstra√ß√£o"""
    try:
        # Simular processamento
        await asyncio.sleep(2)
        
        # Criar arquivo de sa√≠da mock
        output_dir = "uploads/converted"
        os.makedirs(output_dir, exist_ok=True)
        
        target_format = metadata["target_format"]
        output_path = os.path.join(output_dir, f"{file_id}_converted.{target_format}")
        
        # Copiar arquivo original como "convers√£o"
        import shutil
        shutil.copy2(metadata["file_path"], output_path)
        
        # Atualizar metadados
        metadata.update({
            "status": "completed",
            "output_path": output_path,
            "completed_at": datetime.utcnow().isoformat(),
            "conversion_stats": {
                "success": True,
                "mock": True,
                "message": "Convers√£o simulada (PIL n√£o dispon√≠vel)"
            }
        })
        
        # Salvar metadados
        metadata_path = os.path.join(output_dir, f"{file_id}.json")
        with open(metadata_path, "w") as f:
            json.dump(metadata, f, indent=2)
            
    except Exception as e:
        await handle_conversion_error(file_id, metadata, f"Mock conversion error: {e}")

async def handle_conversion_error(file_id: str, metadata: dict, error: str):
    """Lidar com erros de convers√£o"""
    try:
        error_dir = "uploads/failed"
        os.makedirs(error_dir, exist_ok=True)
        
        metadata.update({
            "status": "failed",
            "error": error,
            "failed_at": datetime.utcnow().isoformat()
        })
        
        error_metadata_path = os.path.join(error_dir, f"{file_id}.json")
        with open(error_metadata_path, "w") as f:
            json.dump(metadata, f, indent=2)
            
    except Exception as e:
        logger.error(f"Erro salvando erro de convers√£o: {e}")

# Estat√≠sticas e monitoramento
@router.get("/stats")
async def get_conversion_stats():
    """Estat√≠sticas de convers√µes de imagem"""
    try:
        stats = {
            "total_uploads": 0,
            "total_conversions": 0,
            "total_failures": 0,
            "formats_processed": {},
            "pil_available": PIL_AVAILABLE
        }
        
        # Contar arquivos em cada diret√≥rio
        for status_dir in ["incoming", "converted", "failed"]:
            dir_path = os.path.join("uploads", status_dir)
            if os.path.exists(dir_path):
                json_files = [f for f in os.listdir(dir_path) if f.endswith('.json')]
                
                if status_dir == "incoming":
                    stats["total_uploads"] += len(json_files)
                elif status_dir == "converted":
                    stats["total_conversions"] += len(json_files)
                elif status_dir == "failed":
                    stats["total_failures"] += len(json_files)
        
        return JSONResponse(stats)
        
    except Exception as e:
        logger.error(f"Erro obtendo estat√≠sticas: {e}")
        return JSONResponse({"error": str(e)})

# Endpoints administrativos
@router.delete("/cleanup")
async def cleanup_old_files():
    """Limpeza de arquivos antigos (admin only)"""
    try:
        # TODO: Implementar limpeza baseada em idade dos arquivos
        return JSONResponse({
            "success": True,
            "message": "Limpeza executada",
            "note": "Implementa√ß√£o pendente"
        })
        
    except Exception as e:
        logger.error(f"Erro na limpeza: {e}")
        raise HTTPException(500, f"Erro interno: {str(e)}")

if __name__ == "__main__":
    print("üñºÔ∏è Image Converter FastAPI Router - Pronto!")
    print(f"PIL dispon√≠vel: {PIL_AVAILABLE}")
    print(f"Pre√ßos: {PRICING}")
    print(f"Formatos suportados: {ALLOWED_EXTENSIONS} ‚Üí {OUTPUT_FORMATS}")